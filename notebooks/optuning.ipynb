{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadaf09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47604d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "  \"\"\"\n",
    "  Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "  This function checks if an experiment with the given name exists within MLflow.\n",
    "  If it does, the function returns its ID. If not, it creates a new experiment\n",
    "  with the provided name and returns its ID.\n",
    "\n",
    "  Parameters:\n",
    "  - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "  Returns:\n",
    "  - str: ID of the existing or newly created MLflow experiment.\n",
    "  \"\"\"\n",
    "\n",
    "  if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "      return experiment.experiment_id\n",
    "  else:\n",
    "      return mlflow.create_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4080f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = get_or_create_experiment(\"XGBoost_Duration_3moves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb91259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "def get_train_split(dp):\n",
    "    x = dp.drop(columns=\"winner\")\n",
    "    y = dp.get(\"winner\")\n",
    "    return train_test_split(x, y, random_state=42)\n",
    "\n",
    "\n",
    "def load_raw_dataset(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the CSV dataset from disk.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def filter_to_rated(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Keep only rated games (rated == True).\"\"\"\n",
    "    if 'rated' not in df.columns:\n",
    "        return df.copy()\n",
    "    return df[df['rated'] == True].copy()\n",
    "\n",
    "\n",
    "def remove_duplicate_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop duplicate rows sharing the same game `id` (keep first).\"\"\"\n",
    "    if 'id' not in df.columns:\n",
    "        return df.copy()\n",
    "    return df.drop_duplicates(subset='id', keep='first').copy()\n",
    "\n",
    "\n",
    "def remove_duplicate_games(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Drop duplicates that share the same (created_at, white_id, black_id).\"\"\"\n",
    "    required = {'created_at', 'white_id', 'black_id'}\n",
    "    if not required.issubset(df.columns):\n",
    "        return df.copy()\n",
    "    return df.drop_duplicates(subset=['created_at', 'white_id', 'black_id'], keep='first').copy()\n",
    "\n",
    "\n",
    "def add_game_duration_seconds(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add `time` as seconds between `last_move_at` and `created_at`, then drop both timestamp columns.\"\"\"\n",
    "    cols = {'created_at', 'last_move_at'}\n",
    "    out = df.copy()\n",
    "    if cols.issubset(out.columns):\n",
    "        out['time'] = (\n",
    "                pd.to_datetime(out['last_move_at'], unit='ms') - pd.to_datetime(out['created_at'], unit='ms')\n",
    "        ).dt.total_seconds()\n",
    "        out = out.drop(columns=['last_move_at', 'created_at'])\n",
    "    return out\n",
    "\n",
    "\n",
    "def split_by_duration_variants(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Create two variants:\n",
    "    - dataset_duration: keep only rows where time != 0 and time != 10000.0\n",
    "    - dataset_noduration: drop the `time` column entirely (keep all rows)\n",
    "    If `time` is missing, returns (df copy, df copy without `time`).\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    if 'time' in out.columns:\n",
    "        dataset_duration = out[(out['time'] != 0) & (out['time'] != 10000.0)].copy()\n",
    "        dataset_noduration = out.drop(columns=['time']).copy()\n",
    "    else:\n",
    "        dataset_duration = out.copy()\n",
    "        dataset_noduration = out.copy()\n",
    "    return dataset_duration, dataset_noduration\n",
    "\n",
    "\n",
    "def drop_columns(df: pd.DataFrame, columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"Drop provided columns if present. No-op when `columns` is None or empty.\"\"\"\n",
    "    if not columns:\n",
    "        return df.copy()\n",
    "    return df.drop(columns=columns, errors='ignore').copy()\n",
    "\n",
    "\n",
    "def first_k(s: str, fk: int) -> Optional[str]:\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    parts = s.split()\n",
    "    if len(parts) == 0:\n",
    "        return None\n",
    "    return ' '.join(parts[:fk]) if len(parts) >= fk else s\n",
    "\n",
    "\n",
    "def keep_first_n_moves(\n",
    "        df: pd.DataFrame,\n",
    "        n: int,\n",
    "        only_n: bool = True,\n",
    "        new_column: Optional[str] = None,\n",
    "        add_all_prefix: str = 'moves_'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create truncated move sequences.\n",
    "\n",
    "    - If only_n is True: keep exactly the first n SAN tokens. If `new_column` is None,\n",
    "      overwrite `moves`; otherwise, write to `new_column`.\n",
    "    - If only_n is False: add cumulative columns for k in [1..n] named\n",
    "      f\"{add_all_prefix}{k}\", each containing the first k moves. The original\n",
    "      `moves` column is not preserved.\n",
    "    \"\"\"\n",
    "    if 'moves' not in df.columns:\n",
    "        return df.copy()\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    if only_n:\n",
    "        col = 'moves' if new_column is None else new_column\n",
    "        out[col] = out['moves'].apply(lambda m: first_k(m, n))\n",
    "    else:\n",
    "        for k in range(1, max(1, n) + 1):\n",
    "            out[f\"{add_all_prefix}{k}\"] = out['moves'].apply(lambda m: first_k(m, k))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def clean_chess_data(\n",
    "        file_path: str,\n",
    "        columns_to_drop: Optional[List[str]] = None,\n",
    "        moves_n: Optional[int] = None,\n",
    "        moves_only_n: bool = True,\n",
    "        moves_new_column: Optional[str] = None,\n",
    "        moves_add_all_prefix: str = 'moves_'\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"High-level pipeline that reproduces the notebook cleaning steps.\n",
    "\n",
    "    Steps:\n",
    "    1) load -> 2) filter rated -> 3) remove duplicate ids ->\n",
    "    4) remove duplicate games by (created_at, white_id, black_id) ->\n",
    "    5) add `time` (seconds) and drop raw timestamps ->\n",
    "    6) create two variants: (duration != 0 AND != 10000.0) and (no `time`) ->\n",
    "    7) optionally derive first-n moves (single or cumulative) ->\n",
    "    8) drop requested columns in both variants.\n",
    "\n",
    "    Returns a dict with keys: 'duration', 'noduration'.\n",
    "    \"\"\"\n",
    "    df = load_raw_dataset(file_path)\n",
    "    df = filter_to_rated(df)\n",
    "    df = remove_duplicate_ids(df)\n",
    "    df = remove_duplicate_games(df)\n",
    "    df = add_game_duration_seconds(df)\n",
    "\n",
    "    dataset_duration, dataset_noduration = split_by_duration_variants(df)\n",
    "\n",
    "    # Optionally derive first-n moves on both variants before dropping columns\n",
    "    if moves_n is not None and moves_n > 0:\n",
    "        dataset_duration = keep_first_n_moves(\n",
    "            dataset_duration,\n",
    "            n=moves_n,\n",
    "            only_n=moves_only_n,\n",
    "            new_column=moves_new_column,\n",
    "            add_all_prefix=moves_add_all_prefix,\n",
    "        )\n",
    "        dataset_noduration = keep_first_n_moves(\n",
    "            dataset_noduration,\n",
    "            n=moves_n,\n",
    "            only_n=moves_only_n,\n",
    "            new_column=moves_new_column,\n",
    "            add_all_prefix=moves_add_all_prefix,\n",
    "        )\n",
    "\n",
    "    # Default columns to drop based on the notebook\n",
    "    default_drop = ['id', 'white_id','black_id','opening_name', 'moves']\n",
    "    # Add rated to the columns to drop\n",
    "    default_drop.append('rated')\n",
    "    # Add columns to drop from the columns_to_drop list\n",
    "    if columns_to_drop is not None:\n",
    "        default_drop.extend(columns_to_drop)\n",
    "    cols = columns_to_drop if columns_to_drop is not None else default_drop\n",
    "\n",
    "    dataset_duration = drop_columns(dataset_duration, cols)\n",
    "    dataset_noduration = drop_columns(dataset_noduration, cols)\n",
    "\n",
    "    return {\n",
    "        'duration': dataset_duration,\n",
    "        'noduration': dataset_noduration,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7947219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8049 entries, 9291 to 20057\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   turns           8049 non-null   int64  \n",
      " 1   victory_status  8049 non-null   object \n",
      " 2   winner          8049 non-null   object \n",
      " 3   increment_code  8049 non-null   object \n",
      " 4   white_rating    8049 non-null   int64  \n",
      " 5   black_rating    8049 non-null   int64  \n",
      " 6   opening_eco     8049 non-null   object \n",
      " 7   opening_ply     8049 non-null   int64  \n",
      " 8   time            8049 non-null   float64\n",
      " 9   moves_1         8049 non-null   object \n",
      " 10  moves_2         8049 non-null   object \n",
      " 11  moves_3         8049 non-null   object \n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 817.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_3moves = clean_chess_data(\n",
    "    \"../res/games.csv\",\n",
    "    moves_n=3,\n",
    "    moves_only_n=False\n",
    ")\n",
    "\n",
    "df_duration, df_noduration = df_3moves[\"duration\"], df_3moves[\"noduration\"]\n",
    "\n",
    "df_duration.head()\n",
    "df_duration.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93664196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_ply</th>\n",
       "      <th>time</th>\n",
       "      <th>moves_1</th>\n",
       "      <th>moves_2</th>\n",
       "      <th>moves_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10648</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+8</td>\n",
       "      <td>868</td>\n",
       "      <td>1364</td>\n",
       "      <td>A40</td>\n",
       "      <td>1</td>\n",
       "      <td>6.367</td>\n",
       "      <td>d4</td>\n",
       "      <td>d4 h6</td>\n",
       "      <td>d4 h6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12935</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>10+0</td>\n",
       "      <td>1789</td>\n",
       "      <td>1560</td>\n",
       "      <td>A00</td>\n",
       "      <td>1</td>\n",
       "      <td>12.491</td>\n",
       "      <td>d3</td>\n",
       "      <td>d3 f6</td>\n",
       "      <td>d3 f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>180+0</td>\n",
       "      <td>867</td>\n",
       "      <td>1410</td>\n",
       "      <td>A00</td>\n",
       "      <td>1</td>\n",
       "      <td>5.008</td>\n",
       "      <td>e3</td>\n",
       "      <td>e3 e6</td>\n",
       "      <td>e3 e6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10637</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>10+2</td>\n",
       "      <td>830</td>\n",
       "      <td>1460</td>\n",
       "      <td>D00</td>\n",
       "      <td>2</td>\n",
       "      <td>7.862</td>\n",
       "      <td>d4</td>\n",
       "      <td>d4 d5</td>\n",
       "      <td>d4 d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9610</th>\n",
       "      <td>2</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>black</td>\n",
       "      <td>0+16</td>\n",
       "      <td>2159</td>\n",
       "      <td>1500</td>\n",
       "      <td>B01</td>\n",
       "      <td>2</td>\n",
       "      <td>23.024</td>\n",
       "      <td>e4</td>\n",
       "      <td>e4 d5</td>\n",
       "      <td>e4 d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>5+8</td>\n",
       "      <td>1341</td>\n",
       "      <td>952</td>\n",
       "      <td>A00</td>\n",
       "      <td>1</td>\n",
       "      <td>8.110</td>\n",
       "      <td>e3</td>\n",
       "      <td>e3 c6</td>\n",
       "      <td>e3 c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+8</td>\n",
       "      <td>1025</td>\n",
       "      <td>1328</td>\n",
       "      <td>D00</td>\n",
       "      <td>2</td>\n",
       "      <td>6.711</td>\n",
       "      <td>d4</td>\n",
       "      <td>d4 d5</td>\n",
       "      <td>d4 d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>5+8</td>\n",
       "      <td>904</td>\n",
       "      <td>1353</td>\n",
       "      <td>C20</td>\n",
       "      <td>2</td>\n",
       "      <td>6.492</td>\n",
       "      <td>e4</td>\n",
       "      <td>e4 e5</td>\n",
       "      <td>e4 e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11469</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>10+0</td>\n",
       "      <td>1027</td>\n",
       "      <td>831</td>\n",
       "      <td>B01</td>\n",
       "      <td>2</td>\n",
       "      <td>4.155</td>\n",
       "      <td>e4</td>\n",
       "      <td>e4 d5</td>\n",
       "      <td>e4 d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>2</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>180+0</td>\n",
       "      <td>897</td>\n",
       "      <td>1375</td>\n",
       "      <td>B07</td>\n",
       "      <td>2</td>\n",
       "      <td>6.318</td>\n",
       "      <td>e4</td>\n",
       "      <td>e4 d6</td>\n",
       "      <td>e4 d6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       turns victory_status winner increment_code  white_rating  black_rating  \\\n",
       "10648      2         resign  black            5+8           868          1364   \n",
       "12935      2         resign  black           10+0          1789          1560   \n",
       "9970       2         resign  black          180+0           867          1410   \n",
       "10637      2         resign  black           10+2           830          1460   \n",
       "9610       2      outoftime  black           0+16          2159          1500   \n",
       "10659      2         resign  white            5+8          1341           952   \n",
       "10664      2         resign  black            5+8          1025          1328   \n",
       "10654      2         resign  black            5+8           904          1353   \n",
       "11469      2         resign  white           10+0          1027           831   \n",
       "9978       2         resign  black          180+0           897          1375   \n",
       "\n",
       "      opening_eco  opening_ply    time moves_1 moves_2 moves_3  \n",
       "10648         A40            1   6.367      d4   d4 h6   d4 h6  \n",
       "12935         A00            1  12.491      d3   d3 f6   d3 f6  \n",
       "9970          A00            1   5.008      e3   e3 e6   e3 e6  \n",
       "10637         D00            2   7.862      d4   d4 d5   d4 d5  \n",
       "9610          B01            2  23.024      e4   e4 d5   e4 d5  \n",
       "10659         A00            1   8.110      e3   e3 c6   e3 c6  \n",
       "10664         D00            2   6.711      d4   d4 d5   d4 d5  \n",
       "10654         C20            2   6.492      e4   e4 e5   e4 e5  \n",
       "11469         B01            2   4.155      e4   e4 d5   e4 d5  \n",
       "9978          B07            2   6.318      e4   e4 d6   e4 d6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample of the dataset with turns < 3\n",
    "df_duration[df_duration['turns'] < 3].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49404f13",
   "metadata": {},
   "source": [
    "We need to convert the object columns:\n",
    "```\n",
    " 0   turns           8049 non-null   int64  \n",
    " 1   victory_status  8049 non-null   object \n",
    " 2   winner          8049 non-null   object \n",
    " 3   increment_code  8049 non-null   object \n",
    " 4   white_rating    8049 non-null   int64  \n",
    " 5   black_rating    8049 non-null   int64  \n",
    " 6   opening_eco     8049 non-null   object \n",
    " 7   opening_ply     8049 non-null   int64  \n",
    " 8   time            8049 non-null   float64\n",
    " 9   moves_1         8049 non-null   object \n",
    " 10  moves_2         8049 non-null   object \n",
    " 11  moves_3         8049 non-null   object \n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Ensure target exists\n",
    "assert \"winner\" in df_duration.columns, f\"winner not in: {df_duration.columns.tolist()}\"\n",
    "\n",
    "# Define features/target\n",
    "X = df_duration.drop(columns=[\"winner\"])\n",
    "y = df_duration[\"winner\"].copy()\n",
    "\n",
    "# Split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Encode y\n",
    "le = LabelEncoder()\n",
    "train_y_enc = le.fit_transform(train_y)\n",
    "valid_y_enc = le.transform(valid_y)\n",
    "\n",
    "# Build preprocessing strictly from X (no 'winner' here)\n",
    "cat_cols = X.select_dtypes(['object']).columns\n",
    "num_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # sklearn >=1.2\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)         # sklearn <1.2\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', ohe, cat_cols),\n",
    "    ('num', 'passthrough', num_cols),\n",
    "])\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', XGBClassifier(objective='multi:softprob', num_class=len(le.classes_))),\n",
    "])\n",
    "\n",
    "# Fit\n",
    "model.fit(train_x, train_y_enc)\n",
    "\n",
    "# Optional: encoded features (pandas DataFrame)\n",
    "X_train_enc = model[:-1].transform(train_x)\n",
    "X_valid_enc = model[:-1].transform(valid_x)\n",
    "\n",
    "# Predict (decoded back to original labels)\n",
    "y_pred_enc = model.predict(valid_x)\n",
    "y_pred = le.inverse_transform(y_pred_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a42242d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888198757763976\n",
      "[[ 801    1  264]\n",
      " [   2  100    0]\n",
      " [ 242    1 1004]]\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(valid_y, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde4064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tony Hu\\.conda\\envs\\iaesiee\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tony Hu\\.conda\\envs\\iaesiee\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator FunctionTransformer from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tony Hu\\.conda\\envs\\iaesiee\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ColumnTransformer from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\Tony Hu\\.conda\\envs\\iaesiee\\lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      "    turns victory_status increment_code  white_rating  black_rating  \\\n",
      "0     61           mate            5+8          1338          1306   \n",
      "\n",
      "  opening_eco  opening_ply    time moves_1 moves_2   moves_3       moves_4  \\\n",
      "0         A10            1  413.74      c4   c4 b6  c4 b6 d4  c4 b6 d4 Bb7   \n",
      "\n",
      "            moves_5  \n",
      "0  c4 b6 d4 Bb7 Nc3  \n",
      "Prediction: [2]\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "filepath = \"C:\\School\\MagnusIA\\models\\duration-5-False\\mlflow_model\"\n",
    "model = mlflow.sklearn.load_model(filepath)\n",
    "\n",
    "df_5moves = clean_chess_data(\n",
    "    \"../res/games.csv\",\n",
    "    moves_n=5,\n",
    "    moves_only_n=False\n",
    ")[\"duration\"]\n",
    "\n",
    "# Create a sample row matching the specified convention\n",
    "import pandas as pd\n",
    "\n",
    "# Winner is white\n",
    "sample = pd.DataFrame({\n",
    "    'turns': [61],\n",
    "    'victory_status': ['mate'],\n",
    "    'increment_code': ['5+8'],\n",
    "    'white_rating': [1338],\n",
    "    'black_rating': [1306],\n",
    "    'opening_eco': ['A10'],\n",
    "    'opening_ply': [1],\n",
    "    'time': [413.74],\n",
    "    'moves_1': ['c4'],\n",
    "    'moves_2': ['c4 b6'],\n",
    "    'moves_3': ['c4 b6 d4'],\n",
    "    'moves_4': ['c4 b6 d4 Bb7'],\n",
    "    'moves_5': ['c4 b6 d4 Bb7 Nc3']\n",
    "})\n",
    "\n",
    "# Predict on the sample\n",
    "prediction = model.predict(sample)\n",
    "print(\"Sample:\\n\", sample)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bece7ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turns                           61\n",
      "victory_status                mate\n",
      "increment_code                 5+8\n",
      "white_rating                  1338\n",
      "black_rating                  1306\n",
      "opening_eco                    A10\n",
      "opening_ply                      1\n",
      "time                        413.74\n",
      "moves_1                         c4\n",
      "moves_2                      c4 b6\n",
      "moves_3                   c4 b6 d4\n",
      "moves_4               c4 b6 d4 Bb7\n",
      "moves_5           c4 b6 d4 Bb7 Nc3\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "row_data = sample.iloc[0]\n",
    "print(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56370c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaesiee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
